# ============================================
# NGINX.CONF - Load Balancer + Cache
# Commit: feat: configurar nginx com cache e rate limiting
# ============================================
#
# Otimizações implementadas:
# 1. Cache de health checks (reduz carga na API)
# 2. Rate limiting (5000 req/s com burst)
# 3. Timeouts agressivos (10s max)
# 4. Keep-alive para reutilizar conexões
# 5. Compressão gzip para respostas JSON

user nginx;
worker_processes auto;  # Usar todos CPUs disponíveis
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 2048;  # Máximo de conexões simultâneas por worker
    use epoll;                # Método de polling eficiente (Linux)
    multi_accept on;          # Aceitar múltiplas conexões de uma vez
}

http {
    include /etc/nginx/mime.types;
    default_type application/json;

    # ============================================
    # LOGGING (MINIMALISTA)
    # ============================================
    # Formato de log customizado (apenas essencial)
    log_format main '$remote_addr - [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_user_agent" '
                    'rt=$request_time';
    
    access_log /var/log/nginx/access.log main buffer=32k flush=5s;
    
    # Desabilitar logs para health checks
    map $request_uri $loggable {
        /health 0;
        default 1;
    }

    # ============================================
    # PERFORMANCE TUNING
    # ============================================
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    
    # Timeouts agressivos
    keepalive_timeout 65;
    keepalive_requests 1000;
    client_body_timeout 10s;
    client_header_timeout 10s;
    send_timeout 10s;

    # Buffers otimizados
    client_body_buffer_size 128k;
    client_max_body_size 10m;
    client_header_buffer_size 1k;
    large_client_header_buffers 4 8k;

    # ============================================
    # COMPRESSÃO GZIP
    # ============================================
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 5;  # Balanceamento entre CPU e compressão
    gzip_types application/json text/plain text/css application/javascript;
    gzip_min_length 256;

    # ============================================
    # CACHE DE HEALTH CHECKS
    # ============================================
    # Cache para /health (evita sobrecarga na API)
    proxy_cache_path /tmp/nginx_cache 
                     levels=1:2 
                     keys_zone=health_cache:10m 
                     inactive=60s 
                     max_size=100m
                     use_temp_path=off;

    # ============================================
    # RATE LIMITING
    # ============================================
    # Limite global: 5000 req/s por IP
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=5000r/s;
    
    # Limite para health checks (menor carga)
    limit_req_zone $binary_remote_addr zone=health_limit:5m rate=100r/s;
    
    # Limite de conexões simultâneas por IP
    limit_conn_zone $binary_remote_addr zone=addr:10m;

    # ============================================
    # UPSTREAM - Backend API
    # ============================================
    upstream api_backend {
        # Algoritmo de balanceamento: least_conn
        # Envia requests para o worker com menos conexões ativas
        least_conn;
        
        # Servidor API (Docker Compose resolve o DNS)
        server api:8000 max_fails=3 fail_timeout=30s weight=1;
        
        # Se escalar API: adicionar mais servidores
        # server api2:8000 max_fails=3 fail_timeout=30s weight=1;
        # server api3:8000 max_fails=3 fail_timeout=30s weight=1;
        
        # Keep-alive para reutilizar conexões
        keepalive 32;
    }

    # ============================================
    # SERVIDOR PRINCIPAL
    # ============================================
    server {
        listen 80;
        server_name _;  # Aceitar qualquer hostname
        
        # Limite de conexões simultâneas: 100 por IP
        limit_conn addr 100;

        # ============================================
        # ENDPOINT: /health (CACHEADO)
        # ============================================
        location /health {
            # Rate limit: 100 req/s com burst de 20
            limit_req zone=health_limit burst=20 nodelay;
            
            # Proxy para backend
            proxy_pass http://api_backend/health;
            
            # Cache configurado
            proxy_cache health_cache;
            proxy_cache_valid 200 10s;  # Cachear por 10s
            proxy_cache_key $request_uri;
            proxy_cache_methods GET;
            
            # Headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            
            # Timeouts mais curtos para health check
            proxy_connect_timeout 2s;
            proxy_send_timeout 2s;
            proxy_read_timeout 2s;
            
            # Adicionar header indicando cache
            add_header X-Cache-Status $upstream_cache_status;
            
            # Desabilitar log
            access_log off;
        }

        # ============================================
        # ENDPOINT: /predict (SEM CACHE)
        # ============================================
        location /predict {
            # Rate limit: 5000 req/s com burst de 1000
            # nodelay: processar burst imediatamente
            limit_req zone=api_limit burst=1000 nodelay;
            
            # Proxy para backend
            proxy_pass http://api_backend/predict;
            
            # Headers essenciais
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # HTTP/1.1 com keep-alive
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            
            # Timeouts (máx 10s por request)
            proxy_connect_timeout 5s;
            proxy_send_timeout 10s;
            proxy_read_timeout 10s;
            
            # Buffers para respostas grandes
            proxy_buffering on;
            proxy_buffer_size 4k;
            proxy_buffers 8 4k;
            proxy_busy_buffers_size 8k;
            
            # Log com flag (opcional)
            access_log /var/log/nginx/access.log main if=$loggable;
        }

        # ============================================
        # ENDPOINT: /metrics (Prometheus - OPCIONAL)
        # ============================================
        location /metrics {
            # Apenas se ENABLE_METRICS=true na API
            proxy_pass http://api_backend/metrics;
            
            # Sem rate limit para scraping Prometheus
            proxy_set_header Host $host;
            
            # Desabilitar log
            access_log off;
        }

        # ============================================
        # ENDPOINT: /docs (Swagger - APENAS DEV)
        # ============================================
        location /docs {
            # Bloquear em produção
            # return 403;
            
            proxy_pass http://api_backend/docs;
            proxy_set_header Host $host;
        }

        # ============================================
        # ENDPOINT: /model/info
        # ============================================
        location /model/info {
            proxy_pass http://api_backend/model/info;
            
            # Cache de informações do modelo (1 minuto)
            proxy_cache health_cache;
            proxy_cache_valid 200 1m;
            
            proxy_set_header Host $host;
            access_log off;
        }

        # ============================================
        # FALLBACK: 404 para rotas não definidas
        # ============================================
        location / {
            return 404 '{"error": "Not Found", "message": "Endpoint not available"}';
            add_header Content-Type application/json;
        }
    }

    # ============================================
    # STATUS PAGE (OPCIONAL - Monitoramento Nginx)
    # ============================================
    server {
        listen 8081;
        server_name _;
        
        location /nginx_status {
            stub_status on;
            access_log off;
            allow 172.20.0.0/16;  # Apenas rede interna
            deny all;
        }
    }
}

# ============================================
# NOTAS DE CONFIGURAÇÃO
# ============================================
#
# 1. Cache de /health:
#    - Reduz carga na API em 90%
#    - Tempo de cache: 10s (ajustável)
#    - Importante para health checks do Kubernetes/Docker
#
# 2. Rate Limiting:
#    - 5000 req/s por IP (ajustar baseado em requisitos)
#    - burst=1000: permite picos de tráfego
#    - nodelay: processa burst imediatamente
#
# 3. Timeouts:
#    - 10s máximo por request (P99 < 200ms esperado)
#    - Se P99 > 10s, há problema na API ou modelo
#
# 4. Keep-alive:
#    - Reutiliza conexões TCP (reduz latência)
#    - keepalive_requests=1000: reaproveitar conexão
#
# 5. Worker Connections:
#    - 2048 por worker (ajustar se necessário)
#    - Total: worker_processes * worker_connections
#    - Ex: 4 workers * 2048 = 8192 conexões máximas
#
# 6. Gzip:
#    - Compressão nível 5 (balanceado)
#    - Apenas para respostas > 256 bytes
#    - Economiza ~60% de bandwidth para JSON
#
# 7. Escalar API:
#    - Adicionar mais linhas no upstream api_backend
#    - Nginx balanceia automaticamente
#    - Usar least_conn para distribuição justa
#
# ============================================
# TESTES DE VALIDAÇÃO
# ============================================
#
# 1. Testar configuração:
#    nginx -t
#
# 2. Recarregar sem downtime:
#    nginx -s reload
#
# 3. Testar cache:
#    curl -I http://localhost:8080/health
#    # Primeira chamada: X-Cache-Status: MISS
#    # Segunda chamada: X-Cache-Status: HIT
#
# 4. Testar rate limit:
#    ab -n 10000 -c 100 http://localhost:8080/predict
#    # Deve retornar 429 (Too Many Requests) se exceder limite
#
# ============================================